{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use AutoEncoding with force_torque_sensor\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "Datasets paper: https://arxiv.org/pdf/1807.06749.pdf\n",
    "\n",
    "Download: https://ibm.ent.box.com/s/vw4y576xlz6ujblpl3gz9c5ttu51qc18\n",
    "\n",
    "Modified by github : \"Variational Autoencoder & Conditional Variational Autoenoder on MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/anaconda2/envs/clustering/lib/python3.5/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "sides_3 = np.load('../data/force_torque_sensor/Dataset/3_sides/Data/data.npy')\n",
    "# sides_4 = np.load('../data/force_torque_sensor/Dataset/4_sides/Data/data.npy')\n",
    "# sides_5 = np.load('../data/force_torque_sensor/Dataset/5_sides/Data/data.npy')\n",
    "# sides_6 = np.load('../data/force_torque_sensor/Dataset/6_sides/Data/data.npy')\n",
    "# sides_200 = np.load('../data/force_torque_sensor/Dataset/200_sides/Data/data.npy')\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# cmap=plt.cm.get_cmap(plt.cm.viridis,143)\n",
    "\n",
    "\n",
    "# # plt.rcParams['font.size'] = 11.\n",
    "# # plt.rcParams['font.family'] = 'Comic Sans MS'\n",
    "# # plt.rcParams['axes.labelsize'] = 15.\n",
    "# # plt.rcParams['xtick.labelsize'] = 10.\n",
    "# # plt.rcParams['ytick.labelsize'] = 10.\n",
    "\n",
    "# plt.figure(figsize=(30,10))\n",
    "\n",
    "\n",
    "\n",
    "# sides = sides_3\n",
    "# print(len(sides))\n",
    "\n",
    "# Force_x = sides[:,0] \n",
    "# Force_y = sides[:,1]\n",
    "# Force_z = sides[:,2]\n",
    "# Moment_x = sides[:,3]\n",
    "# Moment_y = sides[:,4]\n",
    "# Moment_z = sides[:,5]\n",
    "# Peg_Position_x = sides[:,6]\n",
    "# Peg_Position_y = sides[:,7]\n",
    "# Peg_Position_z = sides[:,8]\n",
    "# Angle = sides[:,9]\n",
    "# Time = sides[:,10]\n",
    "# Counter = sides[:,11]\n",
    "\n",
    "\n",
    "# plt.plot(Time, Force_x, marker='s', linestyle='-', markersize=2, linewidth=1, label='Force_x')\n",
    "# plt.plot(Time, Force_y, marker='o', linestyle='-', markersize=2, linewidth=1, label='Force_y')\n",
    "# plt.plot(Time, Force_z, marker='o', linestyle='-', markersize=2, linewidth=1, label='Force_z')\n",
    "\n",
    "# plt.plot(Time, Moment_x, marker='o', linestyle='-', label='Moment_x')\n",
    "# plt.plot(Time, Moment_y, marker='o', linestyle='-', label='Moment_y')\n",
    "# plt.plot(Time, Moment_z, marker='o', linestyle='-', label='Moment_z')\n",
    "\n",
    "# plt.plot(Time, Peg_Position_x, marker='o', linestyle='-', label='Peg_Position_x')\n",
    "# plt.plot(Time, Peg_Position_y, marker='o', linestyle='-', label='Peg_Position_y')\n",
    "# plt.plot(Time, Peg_Position_z, marker='o', linestyle='-', label='Peg_Position_z')\n",
    "\n",
    "# plt.plot(Time, Angle, marker='o', linestyle='-', label='Angle')\n",
    "# plt.plot(Time, Counter, marker='o', linestyle='-', label='Counter')\n",
    "\n",
    "\n",
    "# plt.xlabel('Times')\n",
    "# plt.ylabel('Signals')\n",
    "# plt.title('3 Sileds force torque signals')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "\n",
    "from models import VAE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(data):\n",
    "    mu = np.mean(data,axis=0)\n",
    "    std = np.std(data,axis=0)\n",
    "    return (data - mu)/std\n",
    "\n",
    "def un_normalize(normalized_data, input_data):\n",
    "    mu = np.mean(input_data,axis=0)\n",
    "    std = np.std(input_data,axis=0)\n",
    "    return normalized_data*std+mu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_normalize(sides_3)\n",
    "test_data =feature_normalize(sides_3)\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 4\n",
    "# how many samples per batch to load\n",
    "batch_size = 64\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585353\n",
      "19817\n",
      "4955\n"
     ]
    }
   ],
   "source": [
    "latent_size = 2\n",
    "\n",
    "import torch.utils.data\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,\n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,\n",
    "                                           sampler=valid_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print (len(train_data))\n",
    "print (len(train_loader))\n",
    "print (len(valid_loader))\n",
    "# print(len(train_data.size(0)))\n",
    "\n",
    "# print(sides_3[0])\n",
    "# print(np.array([sides_3[0]]).view(-1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (fc1): Linear(in_features=12, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (linear_means): Linear(in_features=8, out_features=2, bias=True)\n",
      "    (linear_log_var): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc3): Linear(in_features=2, out_features=8, bias=True)\n",
      "    (fc4): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (fc5): Linear(in_features=32, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(latent_size=latent_size).float()\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "logs = defaultdict(list)\n",
    "print(vae)\n",
    "\n",
    "use_cuda = torch.cuda.is_available\n",
    "if use_cuda:\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def loss_fn(recon_x, x, mean, log_var):\n",
    "#     BCE = criterion(recon_x.view(-1, 12), x.view(-1, 12))\n",
    "    BCE = criterion(recon_x, x)\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "#     return (BCE + KLD) / x.size(0)\n",
    "    return (BCE + KLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00/20 Batch 0000/19816, Train_loss    7.7590, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0100/19816, Train_loss    1.2314, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0200/19816, Train_loss    1.0893, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0300/19816, Train_loss    1.1263, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0400/19816, Train_loss    1.0006, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0500/19816, Train_loss    1.1698, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0600/19816, Train_loss    0.9969, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0700/19816, Train_loss    0.8659, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0800/19816, Train_loss    0.9489, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 0900/19816, Train_loss    0.8693, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1000/19816, Train_loss    0.9312, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1100/19816, Train_loss    1.0431, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1200/19816, Train_loss    0.9857, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1300/19816, Train_loss    0.9407, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1400/19816, Train_loss    0.8705, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1500/19816, Train_loss    0.9338, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1600/19816, Train_loss    0.9425, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1700/19816, Train_loss    0.9821, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1800/19816, Train_loss    1.1364, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 1900/19816, Train_loss    0.9582, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2000/19816, Train_loss    1.0300, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2100/19816, Train_loss    1.0892, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2200/19816, Train_loss    0.9832, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2300/19816, Train_loss    0.9412, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2400/19816, Train_loss    0.9200, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2500/19816, Train_loss    0.9452, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2600/19816, Train_loss    1.0053, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2700/19816, Train_loss    0.9899, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2800/19816, Train_loss    0.9284, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 2900/19816, Train_loss    1.0214, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3000/19816, Train_loss    0.8535, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3100/19816, Train_loss    0.8240, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3200/19816, Train_loss    1.0086, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3300/19816, Train_loss    0.9150, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3400/19816, Train_loss    1.7732, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3500/19816, Train_loss    1.0190, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3600/19816, Train_loss    0.9296, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3700/19816, Train_loss    0.9967, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3800/19816, Train_loss    0.9873, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 3900/19816, Train_loss    1.0003, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4000/19816, Train_loss    0.9742, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4100/19816, Train_loss    0.9106, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4200/19816, Train_loss    0.9616, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4300/19816, Train_loss    0.9082, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4400/19816, Train_loss    0.9745, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4500/19816, Train_loss    0.9684, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4600/19816, Train_loss    0.9413, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4700/19816, Train_loss    1.3008, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4800/19816, Train_loss    1.0368, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 4900/19816, Train_loss    0.9092, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5000/19816, Train_loss    0.9785, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5100/19816, Train_loss    0.9532, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5200/19816, Train_loss    0.8690, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5300/19816, Train_loss    0.9065, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5400/19816, Train_loss    0.9966, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5500/19816, Train_loss    0.8751, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5600/19816, Train_loss    1.0062, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5700/19816, Train_loss    1.0070, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5800/19816, Train_loss    0.9417, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 5900/19816, Train_loss    0.9329, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6000/19816, Train_loss    0.9983, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6100/19816, Train_loss    1.0816, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6200/19816, Train_loss    0.9486, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6300/19816, Train_loss    0.8762, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6400/19816, Train_loss    0.9340, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6500/19816, Train_loss    1.0840, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6600/19816, Train_loss    0.9277, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6700/19816, Train_loss    1.0254, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6800/19816, Train_loss    0.9791, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 6900/19816, Train_loss    1.0039, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7000/19816, Train_loss    0.9501, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7100/19816, Train_loss    1.0447, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7200/19816, Train_loss    1.0286, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7300/19816, Train_loss    1.0530, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7400/19816, Train_loss    0.9747, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7500/19816, Train_loss    1.0116, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7600/19816, Train_loss    1.0899, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7700/19816, Train_loss    1.1446, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7800/19816, Train_loss    0.9347, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 7900/19816, Train_loss    1.1371, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 8000/19816, Train_loss    1.0640, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 8100/19816, Train_loss    1.1144, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 8200/19816, Train_loss    1.6097, Valid_accuary   0.0000\n",
      "Epoch 00/20 Batch 8300/19816, Train_loss    0.8993, Valid_accuary   0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-553baf3ef51d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0minput_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mvalid_recon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_log_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m#                 valid_loss = loss_fn(valid_recon_x, input_valid,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#                                      valid_mean, valid_log_var).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/clustering/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/clustering_mini-experiment/experiments/VAE/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mrecon_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/clustering/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/clustering_mini-experiment/experiments/VAE/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/clustering/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/clustering/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/clustering/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for iteration, d in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            x = d.cuda().float()\n",
    "        else:\n",
    "            x = d.float()\n",
    "        recon_x, mean, log_var, z = vae(x)\n",
    "        loss = loss_fn(recon_x, x, mean, log_var).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logs['loss'].append(loss.item())\n",
    "\n",
    "        if iteration % print_every == 0 or iteration == len(train_loader)-1:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for valid in valid_loader:\n",
    "                if use_cuda:\n",
    "                    input_valid = valid.cuda().float()\n",
    "                else:\n",
    "                    input_valid = valid.float()\n",
    "\n",
    "                valid_recon_x, valid_mean, valid_log_var, valid_z = vae(input_valid)\n",
    "#                 valid_loss = loss_fn(valid_recon_x, input_valid,\n",
    "#                                      valid_mean, valid_log_var).cuda()\n",
    "                valid_loss = criterion(valid_recon_x, input_valid)\n",
    "                total +=1\n",
    "\n",
    "                if valid_loss> -0.015 and valid_loss < 0.015:\n",
    "                    correct += 1\n",
    "\n",
    "            valid_acc = correct / total  \n",
    "            \n",
    "            print(\"Epoch {:02d}/{:02d} Batch {:04d}/{:d}, Train_loss {:9.4f}, Valid_accuary{:9.4f}\".format(\n",
    "                epoch, epochs, iteration, len(train_loader)-1, loss.item(), valid_acc))\n",
    "\n",
    "    torch.save(vae, 'vae.pkl')  \n",
    "        \n",
    "    if loss < 0.001:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(vae.named_parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae, 'vae.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vae = torch.load('vae.pkl')\n",
    "print(vae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Clustering",
   "language": "python",
   "name": "clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
