{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use AutoEncoding with force_torque_sensor__CPU\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "Datasets paper: https://arxiv.org/pdf/1807.06749.pdf\n",
    "\n",
    "Download: https://ibm.ent.box.com/s/vw4y576xlz6ujblpl3gz9c5ttu51qc18\n",
    "\n",
    "Modified by github : \"Variational Autoencoder & Conditional Variational Autoenoder on MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jim/anaconda2/envs/clustering/lib/python3.5/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.24.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "sides_3 = np.load('../data/force_torque_sensor/Dataset/3_sides/Data/data.npy')\n",
    "# sides_4 = np.load('../data/force_torque_sensor/Dataset/4_sides/Data/data.npy')\n",
    "# sides_5 = np.load('../data/force_torque_sensor/Dataset/5_sides/Data/data.npy')\n",
    "# sides_6 = np.load('../data/force_torque_sensor/Dataset/6_sides/Data/data.npy')\n",
    "# sides_200 = np.load('../data/force_torque_sensor/Dataset/200_sides/Data/data.npy')\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# cmap=plt.cm.get_cmap(plt.cm.viridis,143)\n",
    "\n",
    "\n",
    "# # plt.rcParams['font.size'] = 11.\n",
    "# # plt.rcParams['font.family'] = 'Comic Sans MS'\n",
    "# # plt.rcParams['axes.labelsize'] = 15.\n",
    "# # plt.rcParams['xtick.labelsize'] = 10.\n",
    "# # plt.rcParams['ytick.labelsize'] = 10.\n",
    "\n",
    "# plt.figure(figsize=(30,10))\n",
    "\n",
    "\n",
    "\n",
    "# sides = sides_3\n",
    "# print(len(sides))\n",
    "\n",
    "# Force_x = sides[:,0] \n",
    "# Force_y = sides[:,1]\n",
    "# Force_z = sides[:,2]\n",
    "# Moment_x = sides[:,3]\n",
    "# Moment_y = sides[:,4]\n",
    "# Moment_z = sides[:,5]\n",
    "# Peg_Position_x = sides[:,6]\n",
    "# Peg_Position_y = sides[:,7]\n",
    "# Peg_Position_z = sides[:,8]\n",
    "# Angle = sides[:,9]\n",
    "# Time = sides[:,10]\n",
    "# Counter = sides[:,11]\n",
    "\n",
    "\n",
    "# plt.plot(Time, Force_x, marker='s', linestyle='-', markersize=2, linewidth=1, label='Force_x')\n",
    "# plt.plot(Time, Force_y, marker='o', linestyle='-', markersize=2, linewidth=1, label='Force_y')\n",
    "# plt.plot(Time, Force_z, marker='o', linestyle='-', markersize=2, linewidth=1, label='Force_z')\n",
    "\n",
    "# plt.plot(Time, Moment_x, marker='o', linestyle='-', label='Moment_x')\n",
    "# plt.plot(Time, Moment_y, marker='o', linestyle='-', label='Moment_y')\n",
    "# plt.plot(Time, Moment_z, marker='o', linestyle='-', label='Moment_z')\n",
    "\n",
    "# plt.plot(Time, Peg_Position_x, marker='o', linestyle='-', label='Peg_Position_x')\n",
    "# plt.plot(Time, Peg_Position_y, marker='o', linestyle='-', label='Peg_Position_y')\n",
    "# plt.plot(Time, Peg_Position_z, marker='o', linestyle='-', label='Peg_Position_z')\n",
    "\n",
    "# plt.plot(Time, Angle, marker='o', linestyle='-', label='Angle')\n",
    "# plt.plot(Time, Counter, marker='o', linestyle='-', label='Counter')\n",
    "\n",
    "\n",
    "# plt.xlabel('Times')\n",
    "# plt.ylabel('Signals')\n",
    "# plt.title('3 Sileds force torque signals')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "\n",
    "from models import VAE\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(data):\n",
    "    mu = np.mean(data,axis=0)\n",
    "    std = np.std(data,axis=0)\n",
    "    return (data - mu)/std\n",
    "\n",
    "def un_normalize(normalized_data, input_data):\n",
    "    mu = np.mean(input_data,axis=0)\n",
    "    std = np.std(input_data,axis=0)\n",
    "    return normalized_data*std+mu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = feature_normalize(sides_3)\n",
    "test_data =feature_normalize(sides_3)\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 4\n",
    "# how many samples per batch to load\n",
    "batch_size = 8\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585353\n",
      "158536\n",
      "39634\n"
     ]
    }
   ],
   "source": [
    "latent_size = 2\n",
    "\n",
    "import torch.utils.data\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,\n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,\n",
    "                                           sampler=valid_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "print (len(train_data))\n",
    "print (len(train_loader))\n",
    "print (len(valid_loader))\n",
    "# print(len(train_data.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Encoder(\n",
      "    (fc1): Linear(in_features=12, out_features=32, bias=True)\n",
      "    (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (linear_means): Linear(in_features=8, out_features=2, bias=True)\n",
      "    (linear_log_var): Linear(in_features=8, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc3): Linear(in_features=2, out_features=8, bias=True)\n",
      "    (fc4): Linear(in_features=8, out_features=32, bias=True)\n",
      "    (fc5): Linear(in_features=32, out_features=12, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(latent_size=latent_size).float()\n",
    "\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "logs = defaultdict(list)\n",
    "print(vae)\n",
    "\n",
    "# use_cuda = torch.cuda.is_available\n",
    "# if use_cuda:\n",
    "#     vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def loss_fn(recon_x, x, mean, log_var):\n",
    "    BCE = criterion(recon_x.view(-1, 12), x.view(-1, 12))\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return (BCE + KLD) / x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for iteration, d in enumerate(train_loader):\n",
    "#         if use_cuda:\n",
    "#             x = d.cuda().float()\n",
    "#         else:\n",
    "        x = d.float()\n",
    "        recon_x, mean, log_var, z = vae(x)\n",
    "        loss = loss_fn(recon_x, x, mean, log_var).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logs['loss'].append(loss.item())\n",
    "\n",
    "        if iteration % print_every == 0 or iteration == len(train_loader)-1:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for valid in valid_loader:\n",
    "#                 if use_cuda:\n",
    "#                     input_valid = valid.cuda().float()\n",
    "#                 else:\n",
    "                input_valid = valid.float()\n",
    "\n",
    "                valid_recon_x, valid_mean, valid_log_var, valid_z = vae(input_valid)\n",
    "                valid_loss = loss_fn(valid_recon_x, input_valid,\n",
    "                                     valid_mean, valid_log_var)\n",
    "                total +=1\n",
    "\n",
    "                if valid_loss> -0.015 and valid_loss < 0.015:\n",
    "                    correct += 1\n",
    "\n",
    "            valid_acc = correct / total  \n",
    "            \n",
    "            print(\"Epoch {:02d}/{:02d} Batch {:04d}/{:d}, Train_loss {:9.4f}, Valid_accuary{:9.4f}\".format(\n",
    "                epoch, epochs, iteration, len(train_loader)-1, loss.item(), valid_acc))\n",
    "\n",
    "    torch.save(cpu_vae, 'cpu_vae.pkl')  \n",
    "        \n",
    "    if loss < 0.001:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(vae.named_parameters())\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae, 'vae.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "vae = torch.load('vae.pkl')\n",
    "print(vae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Clustering",
   "language": "python",
   "name": "clustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
